<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Custom Object Detector with Bounding Box</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <!-- Apple-specific PWA meta tags -->
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
  <meta name="apple-mobile-web-app-title" content="Custom Object Detector" />
  <link rel="apple-touch-icon" href="icons/apple-icon-180.png" />

  <style>
    body {
      background: #121212;
      color: white;
      font-family: "Segoe UI", Tahoma, Geneva, Verdana, sans-serif;
      margin: 0;
      padding: 20px;
      text-align: center;
    }
    main-container {
      display: block;
    }
    top-bar {
      display: block;
      font-weight: bold;
      font-size: 1.4rem;
      margin-bottom: 10px;
    }
    #camera-container {
      position: relative;
      max-width: 400px;
      margin: auto;
      border-radius: 10px;
      overflow: hidden;
      box-shadow: 0 0 20px rgba(0, 255, 0, 0.5);
    }
    video {
      width: 100%;
      border-radius: 10px;
    }
    #overlay {
      position: absolute;
      top: 0;
      left: 0;
      pointer-events: none;
      width: 100%;
      height: 100%;
      border-radius: 10px;
    }
    #controls {
      margin-top: 10px;
    }
    button {
      background: #00cc44;
      border: none;
      color: white;
      padding: 10px 20px;
      margin: 5px;
      font-size: 1rem;
      border-radius: 5px;
      cursor: pointer;
    }
    button:disabled {
      background: #555;
      cursor: not-allowed;
    }
    #photos {
      display: flex;
      flex-wrap: wrap;
      justify-content: center;
      margin-top: 10px;
      gap: 5px;
    }
    #photos div {
      display: flex;
      flex-direction: column;
      align-items: center;
      margin-bottom: 10px;
    }
    #photos img {
      width: 100px;
      border: 2px solid #00cc44;
      border-radius: 5px;
      cursor: pointer;
      transition: transform 0.2s ease;
    }
    #photos img:hover {
      transform: scale(1.05);
      border-color: #00ee55;
    }
    #photos input {
      margin-top: 4px;
      border-radius: 3px;
      border: none;
      padding: 4px 6px;
      font-size: 0.9rem;
      width: 100px;
      text-align: center;
    }
    #status {
      margin-top: 10px;
      min-height: 1.2rem;
    }
  </style>
</head>
<body>
  <main-container>
    <top-bar>Custom Object Detector with Bounding Box</top-bar>

    <div id="camera-container">
      <video id="video" autoplay playsinline muted></video>
      <canvas id="overlay"></canvas>
    </div>

    <div id="controls">
      <button id="capture-btn">Capture Photo</button>
      <button id="train-btn" disabled>Train Model</button>
      <button id="detect-btn" disabled>Start Detection</button>
      <button id="reset-btn">Reset</button>
    </div>

    <div id="photos"></div>
    <div id="status"></div>
  </main-container>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.2.0/dist/tf.min.js"></script>
  <script>
    const video = document.getElementById("video");
    const overlay = document.getElementById("overlay");
    const captureBtn = document.getElementById("capture-btn");
    const trainBtn = document.getElementById("train-btn");
    const detectBtn = document.getElementById("detect-btn");
    const resetBtn = document.getElementById("reset-btn");
    const photosDiv = document.getElementById("photos");
    const status = document.getElementById("status");

    let capturedImages = [];
    let model;
    let isDetecting = false;
    let featureExtractor, labelToIndex;

    function setStatus(msg) { status.textContent = msg; }

    // Get camera stream
    async function setupCamera() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" } });
        video.srcObject = stream;
        return new Promise((resolve) => {
          video.onloadedmetadata = () => {
            // Set canvas size same as video size
            overlay.width = video.videoWidth;
            overlay.height = video.videoHeight;
            resolve();
          };
        });
      } catch(e) {
        setStatus("Camera access error: " + e.message);
      }
    }
    setupCamera();

    captureBtn.onclick = () => {
      const c = document.createElement("canvas");
      c.width = video.videoWidth;
      c.height = video.videoHeight;
      const ctx = c.getContext("2d");
      ctx.drawImage(video, 0, 0, c.width, c.height); // No mirroring applied here
      const dataUrl = c.toDataURL("image/png");
      capturedImages.push({ imgDataUrl: dataUrl, label: "" });
      renderPhotos();
      setStatus(`Captured ${capturedImages.length} photos.`);
      updateTrainBtn();
    };

    function renderPhotos() {
      photosDiv.innerHTML = "";
      capturedImages.forEach((item, idx) => {
        const img = document.createElement("img");
        img.src = item.imgDataUrl;

        const input = document.createElement("input");
        input.type = "text";
        input.placeholder = "Label";
        input.value = item.label || "";
        input.onchange = () => {
          capturedImages[idx].label = input.value.trim();
          updateTrainBtn();
        };

        const container = document.createElement("div");
        container.appendChild(img);
        container.appendChild(input);
        photosDiv.appendChild(container);
      });
    }

    function updateTrainBtn() {
      const uniqueLabels = new Set(capturedImages.map(i => i.label).filter(l => l));
      trainBtn.disabled = uniqueLabels.size < 2 || capturedImages.length < 3;
    }

    trainBtn.onclick = async () => {
      setStatus("Loading MobileNet feature extractor...");
      const mobilenet = await tf.loadLayersModel("https://storage.googleapis.com/tfjs-models/tfjs/mobilenet_v1_0.25_224/model.json");
      featureExtractor = tf.model({
        inputs: mobilenet.inputs,
        outputs: mobilenet.getLayer("conv_pw_13_relu").output
      });

      const labels = [...new Set(capturedImages.map(i => i.label).filter(l => l))];
      labelToIndex = {};
      labels.forEach((label, i) => labelToIndex[label] = i);

      const xs = [];
      const ys = [];

      setStatus("Processing training images...");
      for (let imgObj of capturedImages) {
        if (!imgObj.label) continue;
        const t = await toTensor(imgObj.imgDataUrl);
        const input = t.expandDims();
        const features = featureExtractor.predict(input);
        xs.push(features);
        ys.push(labelToIndex[imgObj.label]);
        t.dispose();
        input.dispose();
      }

      const xsStack = tf.concat(xs, 0);
      const ysOneHot = tf.oneHot(tf.tensor1d(ys, "int32"), labels.length);

      xs.forEach(t => t.dispose());

      model = tf.sequential();
      model.add(tf.layers.flatten({ inputShape: xsStack.shape.slice(1) }));
      model.add(tf.layers.dense({ units: 100, activation: "relu" }));
      model.add(tf.layers.dropout({ rate: 0.5 }));
      model.add(tf.layers.dense({ units: labels.length, activation: "softmax" }));

      model.compile({
        optimizer: tf.train.adam(0.0001),
        loss: "categoricalCrossentropy",
        metrics: ["accuracy"]
      });

      setStatus("Training model...");
      await model.fit(xsStack, ysOneHot, {
        epochs: 30,
        shuffle: true,
        validationSplit: 0.1,
        callbacks: {
          onEpochEnd: (epoch, logs) => setStatus(`Epoch ${epoch+1}/30 â€” Loss: ${logs.loss.toFixed(3)} Acc: ${(logs.acc*100).toFixed(1)}%`)
        }
      });

      xsStack.dispose();
      ysOneHot.dispose();

      detectBtn.disabled = false;
      setStatus("Training complete. Ready to detect.");
    };

    detectBtn.onclick = () => {
      isDetecting = !isDetecting;
      detectBtn.textContent = isDetecting ? "Stop Detection" : "Start Detection";
      if (isDetecting) detectLoop();
      else {
        const ctx = overlay.getContext("2d");
        ctx.clearRect(0, 0, overlay.width, overlay.height);
      }
    };

    async function detectLoop() {
      if (!isDetecting) return;

      const ctx = overlay.getContext("2d");
      ctx.clearRect(0, 0, overlay.width, overlay.height);
      ctx.drawImage(video, 0, 0, overlay.width, overlay.height); // No mirroring applied here

      const t = tf.tidy(() => tf.image.resizeBilinear(tf.browser.fromPixels(video), [224, 224]).toFloat().div(255).expandDims());
      const features = featureExtractor.predict(t);
      const pred = model.predict(features);
      const data = await pred.data();

      const maxConf = Math.max(...data);
      const maxIndex = data.indexOf(maxConf);
      const label = Object.keys(labelToIndex).find(k => labelToIndex[k] === maxIndex) || "Unknown";

      ctx.lineWidth = 4;
      if (maxConf > 0.5) {
        ctx.strokeStyle = "lime";
        ctx.fillStyle = "lime";
        ctx.font = "24px Arial";
        ctx.strokeRect(10, 10, overlay.width - 20, overlay.height - 20);
        ctx.fillText(`${label} (${(maxConf * 100).toFixed(1)}%)`, 20, 40);
      } else {
        ctx.fillStyle = "red";
        ctx.font = "20px Arial";
        ctx.fillText("No confident detection", 10, 30);
      }

      t.dispose();
      features.dispose();
      pred.dispose();

      requestAnimationFrame(detectLoop);
    }

    resetBtn.onclick = () => {
      capturedImages = [];
      renderPhotos();
      trainBtn.disabled = true;
      detectBtn.disabled = true;
      isDetecting = false;
      detectBtn.textContent = "Start Detection";
      overlay.getContext("2d").clearRect(0, 0, overlay.width, overlay.height);
      setStatus("Reset.");
    };

    function toTensor(dataUrl) {
      return new Promise((res) => {
        const img = new Image();
        img.crossOrigin = "anonymous";
        img.onload = () => {
          const c = document.createElement("canvas");
          c.width = 224;
          c.height = 224;
          const ctx = c.getContext("2d");
          ctx.drawImage(img, 0, 0, 224, 224);
          res(tf.browser.fromPixels(c).toFloat().div(255));
        };
        img.src = dataUrl;
      });
    }
  </script>
</body>
</html>